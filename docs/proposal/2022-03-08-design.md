# MVP design for Linux process runner (LPR)

Created on 2022-03-10 by [@mszostok](http://github.com/mszostok)

## Overview

<!-- toc -->

- [Goal](#goal)
- [Terminology](#terminology)
- [Library](#library)
  * [API](#api)
  * [System resource control](#system-resource-control)
  * [Streaming](#streaming)
    + [Alternatives](#alternatives)
  * [Simplification](#simplification)
- [gRPC API (proto)](#grpc-api-proto)
- [CLI](#cli)
  * [Example of usage](#example-of-usage)
- [Security](#security)
  * [AuthN](#authn)
  * [AuthZ](#authz)
- [Selected technology](#selected-technology)

<!-- tocstop -->

## Goal

Design the MVP Job service that provides functionality to run arbitrary Linux processes. Implemented prototype will be done in Go.

## Terminology

> There are only two hard things in Computer Science: cache invalidation and naming things.
>
> -- Phil Karlton

| Term                 | Description                                                                                                                                                                                                                                                                                                                                |
|----------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Library              | A Go library that is used by Agent. It is written with an assumption to be used also by other 3rd party application.                                                                                                                                                                                                                       |
| Agent                | A server (worker service) that runs on the Linux host and executes requested Jobs.                                                                                                                                                                                                                                                         |
| Job                  | An arbitrary Linux process that is executed. It can be started/stopped, and we can stream the output of it.                                                                                                                                                                                                                                |
| CLI a.k.a Client     | A Go command line interface that allows to interact with the Agent in a user-friendly manner.                                                                                                                                                                                                                                              |
| Kata a.k.a challenge | In case of this project it refers to a software development exercise in which a given problem should be solved without usage of already existing 3rd solutions. For example, this project could be easily solved by creating a wrapper around Podman, Docker, containerd etc. However, non-core functionality can rely on other libraries. |

## Library

The Library has been designed in such a way that it is possible to extend it without breaking the API. Instead of methods that accepts a list of arguments, for example:

```go
Run(ctx context.Context, name, cmd string, args []string) (RunOutput, error)
```

I decided to use a Go struct as an input:

```go
Run(ctx context.Context, in RunInput) (RunOutput, error)
```

In that way, new fields can be added to the `in` argument without breaking the method signature. For example, options like `since`, `tail`, `follow`, can be added to the `StreamInput` struct.

Each method has input and output struct and also `context.Context` that will be used for cancellation. This provides a consistent experience which requires less cognitive overhead when the other methods are used.

Additionally, we can easily attach the `Validate` function to each input struct to gather all validation rules in a single place. For example, validate if all required fields were specified.

```go
func (i *RunInput) Validate() error {
	var issues []string
	if i.Name == "" {
		issues = append(issues, "name is required")
	}
	if i.Command == "" {
		issues = append(issues, "command is required")
	}
	if len(issues) == 0 {
		return nil
	}
	return errors.New(strings.Join(issues, ", "))
}

func (l Service) Run(ctx context.Context, in RunInput) (RunOutput, error) {
	if err := in.Validate(); err != nil {
		return RunOutput{}, fmt.Errorf("while validating input: %w", err)
	}
	// ..
	return RunOutput{}, nil
}
```

For the Library constructor, the functional options are used. This approach also provides an option to add more configuration in the future. Another benefit, is that if the Library users don't want to tweak any configuration they can simply write:

```go
func main() {
	svc := job.NewService()
}
```

And only if necessary, change default settings via:

```go
func main() {
	svc := job.NewService(WithGlobalTimeout(time.Second * 30))
}
```

**Additional requirements:**

- No hard-coded logging, such as `fmt.Println`.
- Gracefully stop the process with `cmd.Process.Signal(syscall.SIGTERM)`. If a process is still running after a configured graceful period, it will be killed via `cmd.Process.Kill()`.
- Allow a graceful shutdown for all started processes. This will be used by the Agent in the signal of a shutdown request.

### API

```go mdox-exec="cat pkg/job/service.go"
package job

import (
	"context"
	"time"
)

// Status specifies human-readable Job status.
type Status string

const (
	Running   Status = "RUNNING"
	Failed    Status = "FAILED"
	Succeeded Status = "SUCCEEDED"
)

// Service provides functionality to run/stop/watch arbitrary Linux processes.
type Service struct{}

func NewService(opts ...ServiceOption) *Service {
	o := &ServiceOptions{}
	for _, opt := range opts {
		opt(o)
	}

	return &Service{}
}

type RunInput struct {
	// Name specifies Job name.
	Name string
	// Command is the path of the command to run.
	Command string
	// Args holds command line arguments.
	Args []string
	// Env specifies the environment of the process.
	// Each entry is of the form "key=value".
	Env []string
	// TODO: Resources specifies Job's system resources limits.
	// In the first version not supported. Use globals defined on Agent side.
	//Resources Resources
}

type RunOutput struct{}

func (l *Service) Run(ctx context.Context, in RunInput) (RunOutput, error) {
	return RunOutput{}, nil
}

type GetInput struct {
	// Name specifies Job name.
	Name string
}

type GetOutput struct {
	// CreatedBy specifies the tenant that executed a given Job.
	CreatedBy string
	// Status of a given Job.
	Status Status
	// ExitCode of the exited process.
	ExitCode int
}

func (l *Service) Get(ctx context.Context, in GetInput) (GetOutput, error) {
	return GetOutput{}, nil
}

type StreamLogsInput struct {
	// Name specifies Job name.
	Name string
}

type StreamLogsOutput struct {
	// Output represents the streamed Job logs. It is from start of Job execution.
	Output <-chan string
	// Error allows communicating issues encountered during logs streaming.
	Error <-chan error
}

func (l *Service) StreamLogs(ctx context.Context, in StreamLogsInput) (StreamLogsOutput, error) {
	return StreamLogsOutput{}, nil
}

type StopInput struct {
	// Name specifies Job name.
	Name string
	// GracePeriod represents a period of time given to the Job to terminate gracefully.
	GracePeriod time.Duration
}

type StopOutput struct {
	// Status of a given Job.
	Status Status
	// ExitCode of the exited process.
	ExitCode int
}

func (l *Service) Stop(ctx context.Context, in StopInput) (StopOutput, error) {
	return StopOutput{}, nil
}
```

### System resource control

The scheduled workloads' system resources such as CPU, Memory and IO will be controlled and limited by cgroup v2.

**Steps**

- Agent checks if `/sys/fs/cgroup/cgroup.controllers` is present on the host to ensure that we can use cgroup v2.
- Agent ensures that required controllers are available for the immediate children groups of `/sys/fs/cgroup/`. In general, the `cgroup.subtree_control` should have:
  - `+cpu`
  - `+io`
  - `+memory`
- Agent creates `/sys/fs/cgroup/LPR/{job_name}/` for each Job with proper CPU, Memory and IO settings.

  > **NOTE:** the `/sys/fs/cgroup/LPR/cgroup.subtree_control` also must have required controllers added.

There are libraries that simplify the usage of cgroups, such as [`containerd/cgrups`](https://github.com/containerd/cgroups) but they won't be used as it is against the Kata rules.

### Streaming

Both `stdout` and `stderr` need to be captured. The output will be redirected to a log file. Each started process will have the own log file.
To simplify the solutions in the first version, there won't be any special multiplexing of `stdout` and `stderr`. As a result, there won't be any option on client side to separate `stdout` and `stderr.
The output has a string and error channels.

```go
type StreamLogsOutput struct {
	// Output represents the streamed Job logs. It is from start of Job execution.
	Output <-chan string
	// Error allows communicating issues encountered during logs streaming.
	Error <-chan error
}

func (l Service) StreamLogs(ctx context.Context, in StreamLogsInput) (StreamLogsOutput, error) {
	return StreamLogsOutput{}, nil
}
```

Each stream call spawns a new goroutine that handles the streaming. It's up to the caller to close the context specified as an argument for `StreamLogs(ctx, in)` when stream is not needed anymore.
Internal implementation can be compared to how the Informers works in Kubernetes. First, it executes List and then Watch. Here we will do the same, first open a file and send the current content and later add a file watcher to get `WRITE` and `REMOVED` events. We can use already existing solutions such as [`fsnotify`](https://github.com/fsnotify/fsnotify) or create the own watcher service that implements the Observer pattern.

Buffer size parameters depends on the file system's disk block sizes. Mostly it's `4096` bytes, due to that fact it will be hard-coded on library side to `4096` to not waste reads. In the future, a functional option (`WithReadBufferSize`)can be added to customize that parameter.

#### Alternatives

```go
type StreamLogsOutput struct {
	// Output represents the streamed Job logs. It is from start of Job execution.
	Output io.ReadCloser
}
```

It will be better as the native Go approach with `io.ReadCloser` allows to not only fetch the logs but also informs the Library to close opened resources when client stops watching. It can be done via `Output.Close()` which provides the same experience as the well-known `Response.Body.Close()`. To simplify implementation, the channel were selected and the `context.Context` will be used to cancel streaming. If there will be spare time, the `StreamLogsOutput` will be changed in the next iterations.

### Simplification

- Requires a root privilege. In the future, this should be change to delegation where a less privileged user has a write access of the directory and its `cgroup.procs`, `cgroup.threads` and `cgroup.subtree_control` files.
- Doesn't support a dry-run option for running a Job.
- Process output is saved to a log file, but there is no clean-up procedure. This may lead to disk pressure. Log rotation should be done by an external program like `logrotate` to compress and delete old log entries.
- Most parameters will be hard-coded directly in the Library. This can be later exposed and libraries like [`koanf`](github.com/knadh/koanf) or [`viper`](https://github.com/spf13/viper) can be used.
- Library doesn't have any persistence. Information about started process will be stored in-memory. In general, the data created by the Library doesn't require any relations, so in the future key-value store can be used. For example, [Redis](https://redis.io/) as this will provide a fast lookup. Alternatively, a shim can be created to translate storage API to swappable storage drivers.
- There is no stream filtering like:
  - logs since `x`,
  - `n` lines of recent log file,
  - stream only `stdout` or `stderr`,
  - etc.
- Streaming doesn't allow demultiplexing of previously joined `stdout` and `stderr` streams. This can be introduced later and the Library will expose a dedicated helper function to deal with it. Same as Docker does.
- cgroup v2 resources limits will be defined only on the Agent side. Later it can be added also to the `RunInput` struct.
- Job name is required. Later, it can be optional or a new property `generateName` can be added to explicit say to generate a human-readable name. This will reduce the issues with conflict names.
- No audit logs on Agent side.

## gRPC API (proto)

GRPC API to start/stop/get status/stream output of a running process.

```proto mdox-exec="cat proto/job_runner.proto"
syntax = "proto3";

import "google/protobuf/duration.proto";
import "github.com/gogo/protobuf/gogoproto/gogo.proto";

package job_runner;

enum Status {
	RUNNING = 0;
	FAILED = 1;
	SUCCEEDED = 2;
}

message RunRequest {
	// Name specifies Job name.
	string name = 1;
	// Command is the path of the command to run.
	string command = 2;
	// Args holds command line arguments.
	repeated string args = 3;
	// Env specifies the environment of the process.
	// Each entry is of the form "key=value".
	repeated string env = 4;
}

message RunResponse {}

message GetRequest {
	// Name specifies Job name.
	string name = 1;
}

message GetResponse {
	// CreatedBy specifies the tenant that executed a given Job.
	string created_by = 1;
	// Status of a given Job.
	Status status = 2;
	// ExitCode of the exited process.
	int32 exit_code = 3;
}

message StreamLogsRequest {
	// Name specifies Job name.
	string name = 1;
}

message StreamLogsResponse {
	// Output represents the streamed Job logs. It is from start of Job execution.
	// Contains both the stdout and stderr.
	string output = 1;
}

message StopRequest {
	// Name specifies Job name.
	string name = 1;
	// GracePeriod represents a period of time given to the Job to terminate gracefully.
	google.protobuf.Duration  grace_period = 2 [(gogoproto.stdduration) = true];
}

message StopResponse {
	// Status of a given Job.
	Status status = 1;
	// ExitCode of the exited process.
	int32 exit_code = 2;
}

// JobService provides functionality for managing Jobs
service JobService {
	rpc Run(RunRequest) returns (RunResponse){}
	rpc Get(GetRequest) returns (GetResponse){}
	rpc Stop(StopRequest) returns (StopResponse){}
	rpc StreamLogs(StreamLogsRequest) returns (stream StreamLogsResponse) {};
}
```

## CLI

CLI should be able to connect to an Agent to start, stop, get status, and stream output of a Job.

The CLI will be called `lpr` (Linux Process Runner) and follow syntax:

`lpr [noun] [verb]`

We could add a CI GitHub Action with OS matrix, to ensure that works on different OSes.

### Example of usage

**Login**

> **NOTE:** We can allow specifying cert via flag as it's only a file location. Sensitive cannot be specified in this way as it may be captured by malicious software which can see executed processes e.g. via `ps`.

```bash
lpr auth login [--cacert] [--cert] [--key]
```

Examples:

```bash
# Starts interactive mode to ask about host and cert location
lpr auth login

# Specify host and cert path directly
lpr auth login http://example.com --client-cert ~/mycertfile.pem
```

**Logout**

```bash
lpr auth logout
```

Examples:

```bash
# Starts interactive mode to select what server to logout
lpr auth logout

# Logout of a specified Agent server
lpr auth logout http://example.com
```

**Run**

```bash
lpr job run NAME [-f=file] -- <cmd> <arg1> ... <argN>
```

Examples:

```bash
# Runs a given job. Pattern:
lpr job run foo -- /bin/sh -c 'echo "hello"'

# runs a given job described in `job.yaml`
lpr job run -f job.yaml
```

Example `job.yaml` file:

```yaml mdox-exec="cat docs/proposal/assets/job.yaml"
name: "foo"
command: cmd
arguments:
  - arg1
  - arg2
flags:
  a: flag-value
  long-flag: true
  repeated-flag:
    - flag-value1
    - flag-value2
```

This runs `cmd arg1 arg2 -a=flag-value --long-flag=true --repeated-flag=flag-value1 --repeated-flag=flag-value2`

**Logs**

```bash
# Streams the logs for a job
lpr job logs NAME
```

**Get**

```bash
# Returns a given Job overview
lpr job get NAME [-o|--output=json|yaml|table]
```

Output contains:
- created at
- created by
- status - one of `RUNNING`, `FAILED`, `SUCCEEDED`
- exit code

**Stop**

```bash
# gracefully stops a given Job
lpr job stop NAME [--grace-period=duration]
```

Each command can return an error that is written to `stderr`.

## Security

### AuthN

In mTLS, both the Client and Agent have a certificate. Flow:
- Client connects to Agent
- Agent presents its TLS certificate
- Client verifies the Agent's certificate
- Client presents its TLS certificate
- Agent verifies the client's certificate
- Agent grants access

Finally, Client and Agent exchange information over an encrypted TLS connection.

To enable mTLS between Agent and Client, we have to generate:
- CA Root self-signed certificate

  > **NOTE:** It will be used to sign both the Agent and Client certificate. It needs to be stored in secure and trusted environment.

- Agent certificate (server certificate)
- Client certificate

Certificates will be generated using [`openssl`](https://www.openssl.org/) tool. With following configuration:
- X.509
- Signature Algorithm: RSA with 4096 bits
- Digest Algorithm: SHA256
- Cipher used to encrypt the private key file: aes256

### AuthZ

We want to be able to distinguish which tenant connected to the Agent. We have a few options. For example:

1. Use [Custom Certificate Extensions](https://doc.primekey.com/ejbca/ejbca-operations/ejbca-ca-concept-guide/certificate-profiles-overview/custom-certificate-extensions).
2. Use Distinguished Name (DN), where:
   - `commonName` - tenant name
   - `organizationName` - assigned role/scope
3. Send identity in gRPC call metadata:
   - Client may configure the `grpc.DialOption` with `grpc.WithPerRPCCredentials`. We can use e.g. [`oauth.NewOauthAccess`](https://pkg.go.dev/google.golang.org/grpc/credentials/oauth?utm_source=godoc#NewOauthAccess) or add own logic and implement the [PerRPCCredentials](https://pkg.go.dev/google.golang.org/grpc@v1.45.0/credentials#PerRPCCredentials) interface, for example, with Basic Auth.
   - on Agent side, `metadata.FromIncomingContext` is used to extract sent metadata and validated.

All three options have similar implementation LOE. The 3rd option is the most generic one as it may support different authorization options, for example, JWT, Basic Auth, OAuth2, etc. Additionally, it needs only a TLS to ensure that no one can spy the data sent in metadata. So the mTLS is not needed as the identity is sent in the request and not taken from the client certificate. Even though, this is the best option in my opinion, it cannot be used due to Kata restrictions.

**Selected option**
I decided to use the 2nd option just for the demo purposes. Agent will validate the client certificate using a certificate authority (CA). If a user's client certificate is successfully verified, the subject's `commonName` value will be used as the tenant for the request, and `organizationName` as role. Due to that fact, certificates should be securely distributed to the users who will be accessing the Agent.

For the demo purposes, there won't be any extensive RBAC system. There will be only two hardcoded roles on Agent side.

| Role Name | Description                      |
|-----------|----------------------------------|
| `admin`   | Is able to manage all Jobs.      |
| `user`    | Is able to manage only own Jobs. |

## Selected technology

- Go 1.17
  - Go modules
- [Cobra](https://github.com/spf13/cobra)
- [fsnotify](https://github.com/fsnotify/fsnotify)
- [`openssl`](https://www.openssl.org/)
- [testify](https://github.com/stretchr/testify)
- gRPC
  - [Protocol buffer compiler](https://github.com/protocolbuffers/protobuf)
  - Go plugins for the protocol compiler
    - [github.com/gogo/protobuf/protoc-gen-gofast](https://github.com/gogo/protobuf)
- Use code scanning with [CodeQL](https://docs.github.com/en/code-security/code-scanning/automatically-scanning-your-code-for-vulnerabilities-and-errors/about-code-scanning-with-codeql) to identify vulnerabilities and errors in Go code.
- Use [golangci-lint](https://golangci-lint.run/).
- Use [hadolint](https://github.com/hadolint/hadolint) to check Dockerfile.
- Use [Dependabot](https://docs.github.com/en/code-security/supply-chain-security/managing-vulnerabilities-in-your-projects-dependencies/configuring-dependabot-security-updates) to get automated updates.
